# ğŸ¤– Balancing Bot in 3D

<div align="center">

**A real-time reinforcement learning demo: Train an RL agent in Python, deploy it in your browser with Three.js**

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.5+-blue.svg)](https://www.typescriptlang.org/)
[![Three.js](https://img.shields.io/badge/Three.js-r168+-green.svg)](https://threejs.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

[**Live Demo**](#) â€¢ [**Documentation**](#project-structure) â€¢ [**Report Bug**](https://github.com/erenovic/balancing_bot/issues)

</div>

---

## ğŸ¯ Overview

**Balancing Bot** is a full-stack reinforcement learning project that demonstrates the complete ML pipeline from training to deployment:

1. **ğŸ§  Train** a policy using GRPO (Group Relative Policy Optimization) in Python/PyTorch
2. **ğŸ“¦ Export** the trained model to ONNX format for web deployment
3. **ğŸŒ Deploy** in a beautiful Three.js scene running entirely in the browser
4. **ğŸ® Interact** with the bot - push it around and watch the AI agent recover balance in real-time

The project showcases a balancing problem (similar to the classic inverted pendulum/cartpole) where an RL agent learns to keep a 3D object upright on a platform, demonstrating intelligent behavior that's clearly "learned" rather than scripted.

---

## âœ¨ Features

### Backend (Python/PyTorch)
- âœ… Custom Gymnasium environment for 3D balance simulation
- âœ… GRPO implementation for efficient policy training
- âœ… ONNX model export for cross-platform deployment
- âœ… JSON export of normalization statistics
- âœ… Modern Python tooling (Ruff, mypy, pytest)
- âœ… Pre-commit hooks and CI/CD

### Frontend (TypeScript/Three.js)
- âœ… Real-time 3D physics simulation with Three.js
- âœ… ONNX Runtime Web for in-browser inference
- âœ… Interactive controls - push the bot and watch it recover
- âœ… AI ON/OFF toggle to compare behavior
- âœ… Responsive design with camera controls
- âœ… Modern dev tooling (Vite, Biome, Jest)

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.11+** (for training)
- **Node.js 18+** and npm (for frontend)
- Modern web browser with WebGL support

### 1. Train the Agent (Backend)

```bash
# Navigate to backend
cd backend

# Install dependencies
make install-dev

# Train the balancing agent
python -m backend.train

# Export to ONNX
python -m backend.export --model checkpoints/best_model.pt --output models/policy.onnx
```

This will:
- Train a policy to balance the 3D object
- Save checkpoints during training
- Export the best model to ONNX format
- Generate `normalization_stats.json` for the frontend

### 2. Run the Frontend

```bash
# Navigate to frontend
cd frontend

# Install dependencies
npm install

# Copy the trained model
cp ../backend/models/policy.onnx public/models/
cp ../backend/models/normalization_stats.json public/models/

# Start development server
npm run dev
```

Visit `http://localhost:3000` and watch your trained agent balance in 3D!

### 3. Interact with the Bot

- **Click** or **press keys** to push the bot
- Toggle **AI ON/OFF** to see the difference between controlled and uncontrolled behavior
- Use **mouse controls** to rotate the camera and view from different angles

---

## ğŸ—ï¸ Project Structure

```
balancing_bot/
â”œâ”€â”€ backend/                    # Python RL training pipeline
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â”œâ”€â”€ environment.py      # Custom Gymnasium environment
â”‚   â”‚   â”œâ”€â”€ grpo.py            # GRPO algorithm implementation
â”‚   â”‚   â”œâ”€â”€ train.py           # Training script
â”‚   â”‚   â””â”€â”€ export.py          # ONNX export utilities
â”‚   â”œâ”€â”€ tests/                 # Backend tests
â”‚   â”œâ”€â”€ models/                # Saved models and stats (generated)
â”‚   â””â”€â”€ pyproject.toml         # Python dependencies
â”‚
â”œâ”€â”€ frontend/                   # TypeScript/Three.js visualization
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ script.ts          # Main Three.js application
â”‚   â”‚   â”œâ”€â”€ physics.ts         # Physics simulation
â”‚   â”‚   â”œâ”€â”€ inference.ts       # ONNX model inference
â”‚   â”‚   â””â”€â”€ utils/             # Utility functions
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ models/            # ONNX models (copied from backend)
â”‚   â”œâ”€â”€ tests/                 # Frontend tests
â”‚   â””â”€â”€ package.json           # Node dependencies
â”‚
â””â”€â”€ README.md                   # This file
```

---

## ğŸ§ª The Environment

### State Space
- **Tilt angle** (Î¸) - How far from vertical the object is
- **Angular velocity** (Ï‰) - How fast it's rotating
- **Position** (x, z) - Location on the platform
- **Velocity** (vâ‚“, váµ§) - Movement speed

### Action Space
- **Torque** applied to stabilize the object (continuous or discrete)

### Reward Function
- Negative reward for deviation from upright position
- Small penalty for excessive torque (energy efficiency)
- Bonus for maintaining balance over time

### Termination Conditions
- Object falls over (angle > threshold)
- Falls off platform
- Maximum episode length reached

---

## ğŸ“ Technical Deep Dive

### Why GRPO?
Group Relative Policy Optimization is particularly effective for this task because:
- **Fast convergence** on simple control tasks
- **Stable training** with fewer hyperparameters to tune
- **Sample efficient** compared to basic policy gradient methods

### ONNX Pipeline
1. **Training**: PyTorch model learns the policy
2. **Export**: Convert to ONNX using `torch.onnx.export()`
3. **Normalization**: Save input normalization stats as JSON
4. **Import**: Load in browser with `onnxruntime-web`
5. **Inference**: Real-time policy evaluation at 60 FPS

### Three.js Integration
- Physics simulation runs at fixed timestep
- Policy inference happens every frame
- Smooth interpolation for visual quality
- WebGL shaders for performance

---

## ğŸ› ï¸ Development

### Backend Development

```bash
cd backend
make help          # Show all available commands
make fmt           # Format code
make lint          # Lint code
make test          # Run tests
make ci            # Run all checks
```

### Frontend Development

```bash
cd frontend
npm run dev        # Start dev server with hot reload
npm run test       # Run tests
npm run check      # Lint and format
npm run ci         # Run all checks
```

---

## ğŸ“Š Training Tips

### Hyperparameter Tuning
- Start with default GRPO settings
- Adjust learning rate if training is unstable
- Increase batch size for smoother gradients
- Use curriculum learning for complex balance tasks

### Monitoring Training
- Watch episode rewards in TensorBoard
- Check average tilt angle over time
- Monitor policy entropy (exploration vs exploitation)
- Validate on held-out initial conditions

### Debugging
- Visualize episodes in the browser
- Log state transitions
- Plot reward components separately
- Use smaller networks for faster iteration

---

## ğŸ® Customization Ideas

- ğŸ”§ **Different objects**: Pyramid, cylinder, complex shapes
- ğŸŒ **Physics variations**: Different gravity, friction, air resistance
- ğŸ¯ **Advanced tasks**: Moving targets, obstacle avoidance
- ğŸ¨ **Visual effects**: Particles, trails, shaders
- ğŸ† **Challenges**: Timed modes, disturbance patterns
- ğŸ‘¥ **Multi-agent**: Multiple bots balancing together

---

## ğŸ“ˆ Performance Benchmarks

### Training
- **Time to convergence**: ~10-30 minutes on CPU
- **Episodes needed**: ~1000-5000 depending on complexity
- **Model size**: ~50KB (ONNX)

### Inference
- **Browser FPS**: 60 FPS stable
- **Inference time**: <1ms per forward pass
- **Load time**: <100ms for model + scene

---

## ğŸ¤ Contributing

Contributions are welcome! Whether it's:
- ğŸ› Bug fixes
- âœ¨ New features
- ğŸ“š Documentation improvements
- ğŸ¨ UI/UX enhancements

Please feel free to submit a Pull Request.

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¨â€ğŸ’» Author

**Eren Cetin**
- Email: erencetin98@gmail.com
- GitHub: [@erenovic](https://github.com/erenovic)

---

## ğŸ™ Acknowledgments

- **OpenAI Gym/Gymnasium** for the RL environment framework
- **Three.js** for the amazing 3D graphics library
- **ONNX Runtime** for enabling ML in the browser
- **PyTorch** for the deep learning framework

---

## ğŸ—ºï¸ Roadmap

- [ ] Implement GRPO training algorithm
- [ ] Create custom balancing environment
- [ ] ONNX export pipeline
- [ ] Basic Three.js scene with physics
- [ ] ONNX inference in browser
- [ ] Interactive disturbances
- [ ] UI controls (AI toggle, reset, stats)
- [ ] Multiple difficulty levels
- [ ] Mobile support
- [ ] Leaderboard for longest balance time

---

<div align="center">

**Built with â¤ï¸ using PyTorch, Three.js, and ONNX**

â­ Star this repo if you find it interesting!

</div>

